{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3-data_check.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Universidade Federal do Rio Grande do Norte\n"],"metadata":{"id":"goyPEITyIgrq"}},{"cell_type":"markdown","source":["## Programa de Pós-Graduação em Engenharia Elétrica e de Computação\n","## EEC1509 - Aprendizagem de Máquina\n"],"metadata":{"id":"LUZmJlPF5jRb"}},{"cell_type":"markdown","source":["# Group"],"metadata":{"id":"5qhajK4XIgrz"}},{"cell_type":"markdown","source":["## João Lucas Correia Barbosa de Farias"],"metadata":{"id":"_BQVSIsz5UZs"}},{"cell_type":"markdown","source":["## Júlio Freire Peixoto Gomes\n"],"metadata":{"id":"CxH0ijN65aiu"}},{"cell_type":"markdown","source":["# Project 2 - Traffic Sign Recognition\n"],"metadata":{"id":"MOBx6KuK4_v4"}},{"cell_type":"markdown","source":["## About the Project\n","This project is divided in 6 files including this one, where each one represents one step in the process of deploying a machine learning algorithm. In this case, we chose a Neural Network algorithm as Classifier. The goal is to explore learning, generalization and batch-normalization techniques and compare results.\n","\n","The dataset has over 50k images of traffic signs. Our goal is to predict which sign a specific image refers to.\n"],"metadata":{"id":"gkCck3SWIgr0"}},{"cell_type":"markdown","source":["### The details about the dataset are shown below.\n","\n","The German Traffic Sign Benchmark is a multi-class, single-image classification challenge held at the International Joint Conference on Neural Networks (IJCNN) 2011.\n","\n","*   Single-image, multi-class classification problem\n","*   More than 40 classes\n","*   More than 50,000 images in total\n","*   Large, lifelike database\n","\n","For more information, visit:\n","\n","https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n","\n","Also, for each class, that is a respective shape, color and sign id's. They are describred as follows:\n","\n","\n","\n","1.   Shape ID\n","  *   0: red\n","  *   1: blue\n","  *   2: yellow\n","  *   3: white\n","2.   Color ID\n","  *   0: triangle\n","  *   1: circle\n","  *   2: diamond\n","  *   3: hexagon\n","  *   4: inverse-triangle\n","3.   Sign ID\n","  *   float: value according to Ukranian Traffic Rule"],"metadata":{"id":"bidR51Nb5yoC"}},{"cell_type":"markdown","source":["## The dataset was taken from Kaggle:\n","https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009"],"metadata":{"id":"L_RYmp1h53CC"}},{"cell_type":"markdown","source":["# 1.0 Install and Load Libraries\n"],"metadata":{"id":"acco5TRNiLmT"}},{"cell_type":"code","source":["%%capture\n","# install wandb\n","!pip install wandb"],"metadata":{"id":"9fOxI8PGk2zZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%capture\n","# install pytest\n","!pip install pytest pytest-sugar"],"metadata":{"id":"BzZGndBhiXNw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import wandb"],"metadata":{"id":"6AuMnvaFigg-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2.0 Data Check"],"metadata":{"id":"l6hd9lVFiEml"}},{"cell_type":"markdown","source":["After the preprocessing stage, we need to check the data to see if it is in accordance with what we expect"],"metadata":{"id":"zBUb03vvqM_T"}},{"cell_type":"markdown","source":["## 2.1 Login to Weights & Biases"],"metadata":{"id":"29CGvqkXqzgE"}},{"cell_type":"code","source":["# login to wandb\n","!wandb login --relogin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BloO236cqo4B","executionInfo":{"status":"ok","timestamp":1658450480351,"user_tz":180,"elapsed":10984,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"5f100f87-e122-4858-aa0a-56e143b5887d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"markdown","source":["## 2.2 Write a .py file to run pytest on"],"metadata":{"id":"q09s-rqhrp3u"}},{"cell_type":"code","source":["%%file test_data.py\n","import pytest\n","import wandb\n","import numpy as np\n","import h5py\n","\n","# This is global so all tests are collected under the same run\n","run = wandb.init(project=\"traffic_sign_recognition\", job_type=\"data_checks\")\n","\n","@pytest.fixture(scope=\"session\")\n","def data():\n","\n","    train_local_path = run.use_artifact(\"ppgeec-ml-jj/traffic_sign_recognition/preprocessed_data_train.h5:latest\").file()\n","    labels_local_path = run.use_artifact(\"ppgeec-ml-jj/traffic_sign_recognition/preprocessed_data_train_labels.csv:latest\").file()\n","\n","    image_data = []\n","    with h5py.File(train_local_path, 'r') as hf:\n","      images = list(hf.keys())\n","      for img in images:\n","        data = hf[img]\n","        data_array = np.array(data)\n","        image_data.append(np.array(data_array))\n","    image_data = np.array(image_data)\n","\n","    labels = np.loadtxt(labels_local_path, delimiter=',')\n","\n","    tensor = [image_data, labels]\n","\n","    return tensor\n","\n","def test_data_length(data):\n","    \"\"\"\n","    Here we test if the train set has at least 5000 images\n","    \"\"\"\n","    assert len(data[0]) > 5000\n","\n","\n","def test_size_of_imagem(data):\n","    \"\"\"\n","    Here we test if all images have 3 channels (RGB).\n","    \"\"\"\n","\n","    RGB = True\n","\n","    for i in data[0]:\n","      if i.shape[2] != 3:\n","        RGB = False\n","\n","    assert RGB\n","\n","def test_column_ranges(data):\n","\n","    for i in data[0]:\n","      range_img_0 = np.where(i < 0)[0]\n","      range_img_255 = np.where(i > 255)[0]\n","\n","    assert f'Images number {range_img_0} has values less than 0'\n","    assert f'Images number {range_img_255} has values great than 0'\n","\n","def test_num_labels(data):\n","\n","    unique = len(np.unique(data[1]))\n","    min = int(np.min(data[1]))\n","    max = int(np.max(data[1]))\n","\n","    assert unique == 43\n","    assert min == 0\n","    assert max == 42\n","\n","run.finish()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lK-o88qaQi2A","executionInfo":{"status":"ok","timestamp":1658450984140,"user_tz":180,"elapsed":281,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"a2be5a04-66a6-437e-8223-f5d4375a14da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting test_data.py\n"]}]},{"cell_type":"code","source":["# running pytest\n","!pytest . -vv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GL0HFc5DYkKK","executionInfo":{"status":"ok","timestamp":1658451120373,"user_tz":180,"elapsed":13820,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"8041bd30-f4de-45f0-a300-33ce12d3bd55"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1mTest session starts (platform: linux, Python 3.7.13, pytest 3.6.4, pytest-sugar 0.9.5)\u001b[0m\n","cachedir: .pytest_cache\n","rootdir: /content, inifile:\n","plugins: typeguard-2.7.1, sugar-0.9.5\n","\n"," \u001b[36mtest_data.py\u001b[0m::test_data_length\u001b[0m \u001b[32m✓\u001b[0m                                 \u001b[32m25% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█▌       \u001b[0m\n"," \u001b[36mtest_data.py\u001b[0m::test_size_of_imagem\u001b[0m \u001b[32m✓\u001b[0m                              \u001b[32m50% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m██     \u001b[0m\n"," \u001b[36mtest_data.py\u001b[0m::test_column_ranges\u001b[0m \u001b[32m✓\u001b[0m                               \u001b[32m75% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m██\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█▌  \u001b[0m\n"," \u001b[36mtest_data.py\u001b[0m::test_num_labels\u001b[0m \u001b[32m✓\u001b[0m                                 \u001b[32m100% \u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m██\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m█\u001b[0m\u001b[40m\u001b[32m██\u001b[0m\n","\u001b[33m=============================== warnings summary ===============================\u001b[0m\n","test_data.py::test_data_length\n","  /content/test_data.py:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","    image_data = np.array(image_data)\n","\n","-- Docs: http://doc.pytest.org/en/latest/warnings.html\n","\n","Results (12.43s):\n","\u001b[32m       4 passed\u001b[0m\n"]}]}]}