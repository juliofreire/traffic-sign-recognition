{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1-fetch_data.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Universidade Federal do Rio Grande do Norte\n"],"metadata":{"id":"qPczrXCLfD1M"}},{"cell_type":"markdown","source":["## Programa de Pós-Graduação em Engenharia Elétrica e de Computação\n","## EEC1509 - Aprendizagem de Máquina\n"],"metadata":{"id":"LUZmJlPF5jRb"}},{"cell_type":"markdown","source":["# Group"],"metadata":{"id":"rcil4ejSfixb"}},{"cell_type":"markdown","source":["## João Lucas Correia Barbosa de Farias"],"metadata":{"id":"_BQVSIsz5UZs"}},{"cell_type":"markdown","source":["## Júlio Freire Peixoto Gomes\n"],"metadata":{"id":"CxH0ijN65aiu"}},{"cell_type":"markdown","source":["# Project 2 - Traffic Sign Recognition\n"],"metadata":{"id":"MOBx6KuK4_v4"}},{"cell_type":"markdown","source":["## About the Project\n","This project is divided in 6 files including this one, where each one represents one step in the process of deploying a machine learning algorithm. In this case, we chose a Neural Network algorithm as Classifier. The goal is to explore learning, generalization and batch-normalization techniques and compare results.\n","\n","The dataset has over 50k images of traffic signs. Our goal is to predict which sign a specific image refers to.\n"],"metadata":{"id":"nUV8FQ5Xf0o9"}},{"cell_type":"markdown","source":["### The details about the dataset are shown below.\n","\n","The German Traffic Sign Benchmark is a multi-class, single-image classification challenge held at the International Joint Conference on Neural Networks (IJCNN) 2011.\n","\n","*   Single-image, multi-class classification problem\n","*   More than 40 classes\n","*   More than 50,000 images in total\n","*   Large, lifelike database\n","\n","For more information, visit:\n","\n","https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n","\n","Also, for each class, that is a respective shape, color and sign id's. They are describred as follows:\n","\n","\n","\n","1.   Shape ID\n","  *   0: red\n","  *   1: blue\n","  *   2: yellow\n","  *   3: white\n","2.   Color ID\n","  *   0: triangle\n","  *   1: circle\n","  *   2: diamond\n","  *   3: hexagon\n","  *   4: inverse-triangle\n","3.   Sign ID\n","  *   float: value according to Ukranian Traffic Rule"],"metadata":{"id":"bidR51Nb5yoC"}},{"cell_type":"markdown","source":["## The dataset was taken from Kaggle:\n","https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009"],"metadata":{"id":"L_RYmp1h53CC"}},{"cell_type":"markdown","source":["# 1.0 Install and Load Libraries\n"],"metadata":{"id":"acco5TRNiLmT"}},{"cell_type":"code","source":["%%capture\n","!pip install wandb"],"metadata":{"id":"9fOxI8PGk2zZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import wandb"],"metadata":{"id":"6AuMnvaFigg-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2.0 Fetch Data"],"metadata":{"id":"NG2c-1qfSMm7"}},{"cell_type":"markdown","source":["In this first step, the raw data from the dataset is uploaded to wandb. This way, in the following steps, we are able to communicate with wandb and retrieve the dataset."],"metadata":{"id":"zlADQhV3n_Z6"}},{"cell_type":"markdown","source":["First, we import 'numpy' for array operations, 'os' for path-like operations and 'cv2' for dealing with images."],"metadata":{"id":"MAEuxUkiMfnh"}},{"cell_type":"code","source":["import h5py\n","import numpy as np\n","import os\n","from PIL import Image\n","import pandas as pd"],"metadata":{"id":"uclNrw-SLwdD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Since our data is stored in Google Drive, we mounted the drive into Colab and used this to gain access to the dataset."],"metadata":{"id":"TcI1dVMqMsU_"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZEx_lbC5LrUC","executionInfo":{"status":"ok","timestamp":1658803896492,"user_tz":180,"elapsed":26654,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"340ec2d6-6a06-478c-ae26-6d84fec0e384"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"markdown","source":["After mounting the drive, we found out the path to the dataset. For this, use the Files on the tool bar to the left of the screen. Then, find the folder you want the path to and click the three dots (...) to the right of the name of the folder. Finally, click 'copy path'. We used this path to set the following variables."],"metadata":{"id":"wGAeSaR8M74T"}},{"cell_type":"code","source":["# After uploading the data to your Drive and mounting it to Colab, use the path\n","# to the folder with the data to create the following variables.\n","\n","path_to_data = 'path_to_data'\n","path_to_train = os.path.join(path_to_data, 'Train')\n","path_to_test = os.path.join(path_to_data, 'Test')"],"metadata":{"id":"7d0nA5SCL23n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The ratio defined here was used to decrease the number of images we use in our classification problem. This is done because there are over 50k images and it becomes hard to train models and tune hyperparameters using the free version Google Colab. Besides, using 15k images gives good results."],"metadata":{"id":"8ACmB0scf6AL"}},{"cell_type":"code","source":["# The ratio was calculated with the goal of keeping about 15k of the total 50k \n","# images, this way the dataset was reduced to 30% of its original size\n","\n","ratio = 15/50"],"metadata":{"id":"5_QWejUKgSAo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We decided to use HDF5 encoding to gather of images. This is done because using HDF5 makes it easier to upload to W&B. Also, it makes more sense when designing the pipeline, as an HDF5 file can be used as the input.\n","\n","First, we created an HDF5 file for the train set. Here 'ratio' was used to select about only 30% of the images to create the HDF5 file. The labels for each of the selected files were copied to an array."],"metadata":{"id":"piIAjOgVgkci"}},{"cell_type":"code","source":["image_labels = []\n","\n","NUM_LABELS = len(os.listdir(path_to_train)) \n","\n","path_to_train_hdf5 = 'raw_data_train.h5'\n","\n","with h5py.File(path_to_train_hdf5, 'a') as hf:\n","  for i in range(NUM_LABELS):\n","    label = i\n","    folder = os.path.join(path_to_train, str(label))\n","    images = os.listdir(folder)\n","    for img in images:\n","      if np.random.rand() < ratio:\n","        img_name = os.path.join(folder, img)\n","        img_array = np.array(Image.open(img_name))\n","        dset = hf.create_dataset(img, data=img_array)\n","        image_labels.append(label)\n","\n","image_labels = np.array(image_labels)\n","\n","print(f\"Size of HDF5 file: {os.path.getsize(path_to_train_hdf5)}\")\n","print(f\"image_labels.shape: {image_labels.shape}\")"],"metadata":{"id":"P5Vi2wISgj4n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Next, we created the HDF5 file for the test set. Again, 'ratio' was used to select only a portion of the total number of images. We have to make sure to export an array with the corresponding label for each image in the test set. This way, we will be able to evaluate our model later. For this, we use the 'Test.csv' that comes with the dataset and look for the 'ClassId' column."],"metadata":{"id":"HyUY9L6WhPfo"}},{"cell_type":"code","source":["path_to_test_labels = os.path.join(path_to_data, 'Test.csv')\n","df_test_labels = pd.read_csv(path_to_test_labels)"],"metadata":{"id":"Jo9d0-zpZs0I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_to_test_hdf5 = 'raw_data_test.h5'\n","\n","test_labels_1 = []\n","test_labels_2 = []\n","\n","with h5py.File(path_to_test_hdf5, 'a') as hf:\n","  folder = path_to_test\n","  images = os.listdir(folder)\n","  for img in images:\n","    if np.random.rand() < ratio:\n","      Class_ID_name = os.path.join('Test', img)\n","      df_img = df_test_labels[df_test_labels['Path'] == Class_ID_name]\n","      Class_ID = int(df_img['ClassId'])\n","      test_labels_1.append(Class_ID)\n","      test_labels_2.append(img)\n","      img_name = os.path.join(folder, img)\n","      img_array = np.array(Image.open(img_name))\n","      dset = hf.create_dataset(img, data=img_array)\n","\n","test_labels_1 = pd.DataFrame(test_labels_1, columns=['label'])\n","test_labels_2 = pd.DataFrame(test_labels_2, columns=['path'])\n","test_labels = pd.concat(objs=[test_labels_1, test_labels_2], axis=1)\n","\n","print(f\"Size of HDF5 file: {os.path.getsize(path_to_test_hdf5)}\")\n","print(f\"test_labels.shape: {test_labels.shape}\")"],"metadata":{"id":"FVtspHmegj65","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658804203644,"user_tz":180,"elapsed":264111,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"63dcc262-c46b-4560-ce54-a62e914e413f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Size of HDF5 file: 36544546\n","test_labels.shape: (3722, 2)\n"]}]},{"cell_type":"code","source":["test_labels.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"D4Z2uC_ubGTA","executionInfo":{"status":"ok","timestamp":1658804217320,"user_tz":180,"elapsed":11,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"437f3e26-3167-4f0d-a6ec-92491bb956f1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   label       path\n","0      3  11779.png\n","1     39  11272.png\n","2     23  10811.png\n","3     12  10649.png\n","4      4  10880.png"],"text/html":["\n","  <div id=\"df-4666f901-930c-4752-8cf0-b0463073bc1f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>path</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>11779.png</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>39</td>\n","      <td>11272.png</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>23</td>\n","      <td>10811.png</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>12</td>\n","      <td>10649.png</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>10880.png</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4666f901-930c-4752-8cf0-b0463073bc1f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4666f901-930c-4752-8cf0-b0463073bc1f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4666f901-930c-4752-8cf0-b0463073bc1f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":[""],"metadata":{"id":"Av5aYKiSbHdA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"sHCYg3nXcrL2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path_to_test_hdf5 = 'raw_data_test.h5'\n","test_labels = []\n","\n","with h5py.File(path_to_test_hdf5, 'a') as hf:\n","  folder = path_to_test\n","  images = os.listdir(folder)\n","  for img in images:\n","    if np.random.rand() < ratio:\n","      Class_ID_name = os.path.join('Test', img)\n","      df_img = df_test_labels[df_test_labels['Path'] == Class_ID_name]\n","      Class_ID = int(df_img['ClassId'])\n","      test_labels.append(Class_ID)\n","      img_name = os.path.join(folder, img)\n","      img_array = np.array(Image.open(img_name))\n","      dset = hf.create_dataset(img, data=img_array)\n","\n","test_labels = np.array(test_labels)\n","\n","print(f\"Size of HDF5 file: {os.path.getsize(path_to_test_hdf5)}\")\n","print(f\"test_labels.shape: {test_labels.shape}\")"],"metadata":{"id":"glxUVa33Yj1o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"o3fogqvBcsK6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"FozfpwjlcsOi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, we send the HDF5 files to W&B as artifacts. Also, the labels are exported to a csv file and uploaded to W&B as well."],"metadata":{"id":"R0XBKpoBheN4"}},{"cell_type":"code","source":["image_labels.tofile('raw_data_train_labels.csv', sep=',')\n","test_labels.to_csv('raw_data_test_labels.csv', index=False)"],"metadata":{"id":"vaGYjv2ih31N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# login to wandb account\n","!wandb login --relogin"],"metadata":{"id":"KDccuTZjgj-E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658804436321,"user_tz":180,"elapsed":8865,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"73a1d839-e052-4d09-c86d-360b8dbcfdaa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"code","source":["# upload file raw_data_train.h5 (dataset) to wandb under the\n","# project called traffic_sign_recognition\n","\n","!wandb artifact put \\\n","      --name ppgeec-ml-jj/traffic_sign_recognition/raw_data_train.h5 \\\n","      --type raw_data \\\n","      --description \"Raw data train (HDF5 file) from Traffic Sign Recognition Dataset (without labels)\" raw_data_train.h5"],"metadata":{"id":"-I8yvTELh8-p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# upload file raw_data_train_labels.csv (dataset) to wandb under the\n","# project called traffic_sign_recognition\n","\n","!wandb artifact put \\\n","      --name ppgeec-ml-jj/traffic_sign_recognition/raw_data_train_labels.csv \\\n","      --type raw_data \\\n","      --description \"Raw data train from Traffic Sign Recognition Dataset (only labels)\" raw_data_train_labels.csv"],"metadata":{"id":"1wmM6XF3h8-p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# upload file raw_data_test.h5 (dataset) to wandb under the\n","# project called traffic_sign_recognition\n","\n","!wandb artifact put \\\n","      --name ppgeec-ml-jj/traffic_sign_recognition/raw_data_test.h5 \\\n","      --type raw_data \\\n","      --description \"Raw data test (HDF5 file) from Traffic Sign Recognition Dataset\" raw_data_test.h5"],"metadata":{"id":"HPypdcSBh8-p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658804479487,"user_tz":180,"elapsed":9254,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"28c96951-8692-4f4c-ea38-44d470b95a4b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Uploading file raw_data_test.h5 to: \"ppgeec-ml-jj/traffic_sign_recognition/raw_data_test.h5:latest\" (raw_data)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjotafarias\u001b[0m (\u001b[33mppgeec-ml-jj\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20220726_030111-jx6wl53k\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstellar-vortex-302\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition/runs/jx6wl53k\u001b[0m\n","Artifact uploaded, use this artifact in a run by adding:\n","\n","    artifact = run.use_artifact(\"ppgeec-ml-jj/traffic_sign_recognition/raw_data_test.h5:latest\")\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mstellar-vortex-302\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition/runs/jx6wl53k\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220726_030111-jx6wl53k/logs\u001b[0m\n"]}]},{"cell_type":"code","source":["# upload file raw_data_test_labels.csv (dataset) to wandb under the\n","# project called traffic_sign_recognition\n","\n","!wandb artifact put \\\n","      --name ppgeec-ml-jj/traffic_sign_recognition/raw_data_test_labels.csv \\\n","      --type raw_data \\\n","      --description \"Raw data test from Traffic Sign Recognition Dataset (only labels)\" raw_data_test_labels.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iRL9OuUndoyU","executionInfo":{"status":"ok","timestamp":1658804508362,"user_tz":180,"elapsed":9437,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"e1159c96-40e2-4b16-e6c2-764ce802aae3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Uploading file raw_data_test_labels.csv to: \"ppgeec-ml-jj/traffic_sign_recognition/raw_data_test_labels.csv:latest\" (raw_data)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjotafarias\u001b[0m (\u001b[33mppgeec-ml-jj\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.21\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20220726_030140-3kvgwryh\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbumbling-tree-303\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition/runs/3kvgwryh\u001b[0m\n","Artifact uploaded, use this artifact in a run by adding:\n","\n","    artifact = run.use_artifact(\"ppgeec-ml-jj/traffic_sign_recognition/raw_data_test_labels.csv:latest\")\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mbumbling-tree-303\u001b[0m: \u001b[34m\u001b[4mhttps://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition/runs/3kvgwryh\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20220726_030140-3kvgwryh/logs\u001b[0m\n"]}]}]}