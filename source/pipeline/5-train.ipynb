{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5-train.ipynb","provenance":[],"collapsed_sections":["ifNgAGqtJi_D","eTX_Mt8qJi_E"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"6296c6e6730a400c9b0d58369be70a38":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_6294ade44a04443abff93bc4816aa9b2","IPY_MODEL_4475518d40934a3b9737acb9d996cee8"],"layout":"IPY_MODEL_612bc24eba3e4c309bf2abcec5ef614c"}},"6294ade44a04443abff93bc4816aa9b2":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c45fa27c348b479dbeb671203274cdf2","placeholder":"​","style":"IPY_MODEL_6dec1b89936f4ae1b4712127d5cfc863","value":"0.722 MB of 0.722 MB uploaded (0.000 MB deduped)\r"}},"4475518d40934a3b9737acb9d996cee8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_446598b203524760b992858c83838c1a","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6223a6ef3c2444ea89addfc25c39b9f3","value":1}},"612bc24eba3e4c309bf2abcec5ef614c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c45fa27c348b479dbeb671203274cdf2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6dec1b89936f4ae1b4712127d5cfc863":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"446598b203524760b992858c83838c1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6223a6ef3c2444ea89addfc25c39b9f3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"081572d1df78465cbc441fcab5197229":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_5c280ed3306040199b90424546597d4b","IPY_MODEL_42d280c7fe3542f8b776be51663dce00"],"layout":"IPY_MODEL_687c53b426c74f368c742640f9a32297"}},"5c280ed3306040199b90424546597d4b":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8f7b46683b248848f27874a10d680a3","placeholder":"​","style":"IPY_MODEL_04caf498882446c78e8d3db41e7a868c","value":"0.295 MB of 0.295 MB uploaded (0.000 MB deduped)\r"}},"42d280c7fe3542f8b776be51663dce00":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_47874231e64b4c4ab7671f300db966fd","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_138373577409470cb5024d4dc4102a59","value":1}},"687c53b426c74f368c742640f9a32297":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8f7b46683b248848f27874a10d680a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"04caf498882446c78e8d3db41e7a868c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47874231e64b4c4ab7671f300db966fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"138373577409470cb5024d4dc4102a59":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a14f3b33ac446fab5efc5e568e432d7":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_a87d19ab61a2457c9f9c295e3f833bce","IPY_MODEL_7a8c24d6b2914d3b9f0aefa49df37fef"],"layout":"IPY_MODEL_cbb09af9d85a4d3c8bd62e3a3c49f582"}},"a87d19ab61a2457c9f9c295e3f833bce":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_263ad29c3812436b9cad65530a6186cf","placeholder":"​","style":"IPY_MODEL_21abedeecff94652a8916f8c424bee50","value":"0.015 MB of 0.015 MB uploaded (0.000 MB deduped)\r"}},"7a8c24d6b2914d3b9f0aefa49df37fef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_71b488d87f31422e81b8e719ae2d7f54","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc04d5d8fade4eb5a9a254e21b693fe2","value":1}},"cbb09af9d85a4d3c8bd62e3a3c49f582":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"263ad29c3812436b9cad65530a6186cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21abedeecff94652a8916f8c424bee50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"71b488d87f31422e81b8e719ae2d7f54":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc04d5d8fade4eb5a9a254e21b693fe2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Universidade Federal do Rio Grande do Norte\n"],"metadata":{"id":"ifNgAGqtJi_D"}},{"cell_type":"markdown","source":["## Programa de Pós-Graduação em Engenharia Elétrica e de Computação\n","## EEC1509 - Aprendizagem de Máquina\n"],"metadata":{"id":"LUZmJlPF5jRb"}},{"cell_type":"markdown","source":["# Group"],"metadata":{"id":"eTX_Mt8qJi_E"}},{"cell_type":"markdown","source":["## João Lucas Correia Barbosa de Farias"],"metadata":{"id":"_BQVSIsz5UZs"}},{"cell_type":"markdown","source":["## Júlio Freire Peixoto Gomes\n"],"metadata":{"id":"CxH0ijN65aiu"}},{"cell_type":"markdown","source":["# Project 2 - Traffic Sign Recognition\n"],"metadata":{"id":"MOBx6KuK4_v4"}},{"cell_type":"markdown","source":["## About the Project\n","This project is divided in 6 files including this one, where each one represents one step in the process of deploying a machine learning algorithm. In this case, we chose a Neural Network algorithm as Classifier. The goal is to explore learning, generalization and batch-normalization techniques and compare results.\n","\n","The dataset has over 50k images of traffic signs. Our goal is to predict which sign a specific image refers to.\n"],"metadata":{"id":"s3wPlJAKJi_E"}},{"cell_type":"markdown","source":["### The details about the dataset are shown below.\n","\n","The German Traffic Sign Benchmark is a multi-class, single-image classification challenge held at the International Joint Conference on Neural Networks (IJCNN) 2011.\n","\n","*   Single-image, multi-class classification problem\n","*   More than 40 classes\n","*   More than 50,000 images in total\n","*   Large, lifelike database\n","\n","For more information, visit:\n","\n","https://www.kaggle.com/datasets/meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n","\n","Also, for each class, that is a respective shape, color and sign id's. They are describred as follows:\n","\n","\n","\n","1.   Shape ID\n","  *   0: red\n","  *   1: blue\n","  *   2: yellow\n","  *   3: white\n","2.   Color ID\n","  *   0: triangle\n","  *   1: circle\n","  *   2: diamond\n","  *   3: hexagon\n","  *   4: inverse-triangle\n","3.   Sign ID\n","  *   float: value according to Ukranian Traffic Rule"],"metadata":{"id":"bidR51Nb5yoC"}},{"cell_type":"markdown","source":["## The dataset was taken from Kaggle:\n","https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009"],"metadata":{"id":"L_RYmp1h53CC"}},{"cell_type":"markdown","source":["# 1.0 Install and Load Libraries\n"],"metadata":{"id":"acco5TRNiLmT"}},{"cell_type":"code","source":["%%capture\n","# install wandb\n","!pip install wandb"],"metadata":{"id":"9fOxI8PGk2zZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import wandb\n","import logging\n","import pandas as pd\n","import numpy as np\n","import joblib\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import LocalOutlierFactor\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline, FeatureUnion\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.impute import SimpleImputer\n","from sklearn.metrics import fbeta_score, precision_score, recall_score, accuracy_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from imblearn.metrics import geometric_mean_score\n","from sklearn.neural_network import MLPClassifier\n","\n","import h5py\n","import os\n","from PIL import Image\n","\n","from tensorflow import keras\n","\n","from keras.models import Sequential\n","from keras.layers import Conv2D, Dense, Flatten, Dropout, AveragePooling2D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.metrics import Accuracy\n","from tensorflow.keras.layers import Activation\n","\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n","\n","from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy"],"metadata":{"id":"BzZGndBhiXNw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2.0 Login to Weights & Biases"],"metadata":{"id":"29CGvqkXqzgE"}},{"cell_type":"code","source":["# login to wandb\n","!wandb login --relogin"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BloO236cqo4B","executionInfo":{"status":"ok","timestamp":1658801063382,"user_tz":180,"elapsed":35721,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"88b02530-7fff-4d5b-eb81-bc7874cfafff"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]}]},{"cell_type":"markdown","source":["# 3.0 Data Preparation"],"metadata":{"id":"q09s-rqhrp3u"}},{"cell_type":"code","source":["# ratio used to split train and test data\n","val_size = 0.1\n","\n","# seed used to reproduce purposes\n","seed = 13\n","\n","# name of the input artifact\n","artifact_input_name_train = \"traffic_sign_recognition/train.h5:latest\"\n","artifact_input_name_labels = \"traffic_sign_recognition/train_labels.csv:latest\"\n","\n","# type of the artifact\n","artifact_type = \"Train\""],"metadata":{"id":"m0OjcILy7I55"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# initiate wandb project\n","run = wandb.init(project=\"traffic_sign_recognition\", job_type=\"train\")"],"metadata":{"id":"sqiZJDGjAyu8","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1658627620426,"user_tz":180,"elapsed":2157,"user":{"displayName":"JÚLIO GOMES","userId":"17557053208840276455"}},"outputId":"1f263679-b00e-4d9a-b452-23d02d3a2db0"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.21"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20220724_015335-8w48pypf</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition/runs/8w48pypf\" target=\"_blank\">kind-armadillo-179</a></strong> to <a href=\"https://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}}]},{"cell_type":"code","source":["# configure logging\n","logging.basicConfig(level=logging.INFO,\n","                    format=\"%(asctime)s %(message)s\",\n","                    datefmt='%d-%m-%Y %H:%M:%S')\n","\n","# reference for a logging obj\n","logger = logging.getLogger()\n","\n","logger.info(\"Downloading and reading artifact...\")\n","artifact_train = run.use_artifact(artifact_input_name_train)\n","artifact_labels = run.use_artifact(artifact_input_name_labels)\n","\n","artifact_train_path = artifact_train.file()\n","artifact_labels_path = artifact_labels.file()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bFu8gi3PpOsW","executionInfo":{"status":"ok","timestamp":1658627620851,"user_tz":180,"elapsed":431,"user":{"displayName":"JÚLIO GOMES","userId":"17557053208840276455"}},"outputId":"1a7de9fe-25c6-406d-d433-c253f72689f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["24-07-2022 01:53:37 Downloading and reading artifact...\n"]}]},{"cell_type":"code","source":["image_data = []\n","\n","with h5py.File(artifact_train_path, 'r') as hf:\n","  images = list(hf.keys())\n","  for img in images:\n","    data = hf[img]\n","    data_array = np.array(data)\n","    image_data.append(np.array(data_array))\n","\n","train = np.array(image_data)\n","\n","print(f\"train.shape: {train.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2oQF-fdLlP9U","executionInfo":{"status":"ok","timestamp":1658627624770,"user_tz":180,"elapsed":3922,"user":{"displayName":"JÚLIO GOMES","userId":"17557053208840276455"}},"outputId":"62edc7bd-6a5d-4e08-f90d-ec7d145ada00"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train.shape: (11755,)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  # Remove the CWD from sys.path while we load stuff.\n"]}]},{"cell_type":"code","source":["train_labels = np.loadtxt(artifact_labels_path, delimiter=',')\n","print(f\"train_labels.shape: {train_labels.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YlSPDjMflARq","executionInfo":{"status":"ok","timestamp":1658627624772,"user_tz":180,"elapsed":20,"user":{"displayName":"JÚLIO GOMES","userId":"17557053208840276455"}},"outputId":"463668b5-366b-483f-f6b6-0aca41bdcb60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["train_labels.shape: (11755,)\n"]}]},{"cell_type":"markdown","source":["### 3.1 Split Data into Train and Validation Sets"],"metadata":{"id":"7t6xCrPA3zm4"}},{"cell_type":"code","source":["# we will split the train set into training and validation sets\n","logger.info(\"Spliting data into training and validation sets...\")\n","x_train, x_val, y_train, y_val = train_test_split(train,\n","                                                  train_labels,\n","                                                  test_size=val_size,\n","                                                  random_state=seed,\n","                                                  shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G1f9q34FHanB","executionInfo":{"status":"ok","timestamp":1658627624773,"user_tz":180,"elapsed":16,"user":{"displayName":"JÚLIO GOMES","userId":"17557053208840276455"}},"outputId":"d61e76d1-2887-4352-91f8-ce5cbe6355d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["24-07-2022 01:53:42 Spliting data into training and validation sets...\n"]}]},{"cell_type":"code","source":["logger.info(\"x train: {}\".format(x_train.shape))\n","logger.info(\"y train: {}\".format(y_train.shape))\n","logger.info(\"x val: {}\".format(x_val.shape))\n","logger.info(\"y val: {}\".format(y_val.shape))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ITBQ5M12ql3Q","executionInfo":{"status":"ok","timestamp":1658627624773,"user_tz":180,"elapsed":13,"user":{"displayName":"JÚLIO GOMES","userId":"17557053208840276455"}},"outputId":"a6b91817-a2b5-4e10-db19-d6ce7e654203"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["24-07-2022 01:53:42 x train: (10579,)\n","24-07-2022 01:53:42 y train: (10579,)\n","24-07-2022 01:53:42 x val: (1176,)\n","24-07-2022 01:53:42 y val: (1176,)\n"]}]},{"cell_type":"markdown","source":["### 3.2 Base Model Training"],"metadata":{"id":"6QiRtUWc8Utd"}},{"cell_type":"markdown","source":["Number of pixels to resize images"],"metadata":{"id":"6PmgHTTmrhdA"}},{"cell_type":"code","source":["IMAGE_HEIGHT = 30     # pixels\n","IMAGE_WIDTH = 30      # pixels"],"metadata":{"id":"LtQbjch9q2qX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Resize image and normalize values (from 0-255 to 0-1.0) for both x_train and x_val"],"metadata":{"id":"EGT3U2RNrmiQ"}},{"cell_type":"code","source":["x_train_copy = []\n","x_val_copy = []\n","\n","for img in x_train:\n","  image = Image.fromarray(img)\n","  image = image.resize((IMAGE_HEIGHT,IMAGE_WIDTH))\n","  img = np.array(image)\n","  x_train_copy.append(img)\n","\n","for img in x_val:\n","  image = Image.fromarray(img)\n","  image = image.resize((IMAGE_HEIGHT,IMAGE_WIDTH))\n","  img = np.array(image)\n","  x_val_copy.append(img)\n","\n","x_train_copy = np.array(x_train_copy)\n","x_val_copy = np.array(x_val_copy)\n","\n","x_train_copy = x_train_copy/255  \n","x_val_copy = x_val_copy/255"],"metadata":{"id":"uJ8KMOsv8UJk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f\"x_train_copy.shape: {x_train_copy.shape}\")\n","print(f\"x_val_copy.shape: {x_val_copy.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EwTTFDxdstvO","executionInfo":{"status":"ok","timestamp":1658627626131,"user_tz":180,"elapsed":6,"user":{"displayName":"JÚLIO GOMES","userId":"17557053208840276455"}},"outputId":"0abf1a68-8176-4418-df97-8e5993203f20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train_copy.shape: (10579, 30, 30, 3)\n","x_val_copy.shape: (1176, 30, 30, 3)\n"]}]},{"cell_type":"markdown","source":["The LeNet-5 architecture was chosen as the model for our training."],"metadata":{"id":"qWgdGgAv58Pw"}},{"cell_type":"code","source":["lenet5 = Sequential()\n","\n","lenet5.add(Conv2D(6, (5,5), strides=1,  activation='tanh', input_shape=(IMAGE_HEIGHT,IMAGE_WIDTH,3), padding='same')) #C1\n","lenet5.add(AveragePooling2D()) #S2\n","lenet5.add(Conv2D(16, (5,5), strides=1, activation='tanh', padding='valid')) #C3\n","lenet5.add(AveragePooling2D()) #S4\n","lenet5.add(Flatten()) #Flatten\n","lenet5.add(Dense(120, activation='tanh')) #C5\n","lenet5.add(Dense(84, activation='tanh')) #F6\n","lenet5.add(Dense(43, activation='softmax')) #Output layer"],"metadata":{"id":"EiwVpUXgVSRc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lenet5.compile(optimizer='adam',\n","               loss='sparse_categorical_crossentropy', \n","               metrics='accuracy')\n","\n","# training \n","history = lenet5.fit(x=x_train_copy,\n","                    y=y_train,\n","                    batch_size=32,\n","                    epochs=6,\n","                    validation_data=(x_val_copy,y_val))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yUBHby0wV8t7","executionInfo":{"status":"ok","timestamp":1658627711596,"user_tz":180,"elapsed":83117,"user":{"displayName":"JÚLIO GOMES","userId":"17557053208840276455"}},"outputId":"45e70551-0fa7-4844-8635-8c467088ee1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/6\n","331/331 [==============================] - 12s 35ms/step - loss: 2.0442 - accuracy: 0.4627 - val_loss: 0.9487 - val_accuracy: 0.7491\n","Epoch 2/6\n","331/331 [==============================] - 11s 34ms/step - loss: 0.6810 - accuracy: 0.8266 - val_loss: 0.4713 - val_accuracy: 0.8673\n","Epoch 3/6\n","331/331 [==============================] - 11s 34ms/step - loss: 0.3788 - accuracy: 0.9055 - val_loss: 0.3023 - val_accuracy: 0.9286\n","Epoch 4/6\n","331/331 [==============================] - 11s 34ms/step - loss: 0.2540 - accuracy: 0.9400 - val_loss: 0.2268 - val_accuracy: 0.9413\n","Epoch 5/6\n","331/331 [==============================] - 11s 34ms/step - loss: 0.1832 - accuracy: 0.9561 - val_loss: 0.1981 - val_accuracy: 0.9490\n","Epoch 6/6\n","331/331 [==============================] - 11s 34ms/step - loss: 0.1359 - accuracy: 0.9710 - val_loss: 0.1625 - val_accuracy: 0.9626\n"]}]},{"cell_type":"markdown","source":["# 4.0 Pipeline"],"metadata":{"id":"I-IXgUWjulPF"}},{"cell_type":"markdown","source":["Class created to assist in normalizing the dataset array (from 0-255 to 0-1)"],"metadata":{"id":"5JpS1PhH6tQz"}},{"cell_type":"code","source":["class Normalize():\n","  def __init__(self, value=255):\n","    self.value = value\n","\n","  def fit(self, X):\n","    return self\n","\n","  def transform(self, X):\n","    return X/self.value"],"metadata":{"id":"4WNfb51m05wx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.1 Feature Selector"],"metadata":{"id":"3fFIQtAKTViw"}},{"cell_type":"markdown","source":["The input to the pipeline is the x_train set. We will create a class whose sole goal is to return the object itself to be the beginning of the pipeline."],"metadata":{"id":"jMW7BPWLu9M9"}},{"cell_type":"code","source":["class FeatureSelector(BaseEstimator, TransformerMixin):\n","    def fit(self, X, y=None):\n","        return self\n","\n","    def transform(self, X, y=None):\n","        return X"],"metadata":{"id":"7GMvbywxqnA3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fs = FeatureSelector()\n","x_train_fs = fs.fit_transform(x_train)\n","x_train_fs[0]"],"metadata":{"id":"Vs-rs7kJqnHe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658627711598,"user_tz":180,"elapsed":13,"user":{"displayName":"JÚLIO GOMES","userId":"17557053208840276455"}},"outputId":"f6aa83fd-cd7d-4240-d4fc-82cc069c56aa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[143, 127, 142],\n","        [159, 160, 177],\n","        [146, 165, 183],\n","        ...,\n","        [ 40,  36,  45],\n","        [ 51,  45,  57],\n","        [ 60,  55,  71]],\n","\n","       [[155, 143, 146],\n","        [148, 146, 148],\n","        [140, 148, 156],\n","        ...,\n","        [ 32,  32,  38],\n","        [ 32,  31,  35],\n","        [ 30,  30,  33]],\n","\n","       [[139, 130, 127],\n","        [137, 132, 128],\n","        [136, 134, 133],\n","        ...,\n","        [ 39,  42,  48],\n","        [ 38,  41,  46],\n","        [ 37,  41,  45]],\n","\n","       ...,\n","\n","       [[ 31,  44,  47],\n","        [ 29,  41,  44],\n","        [ 30,  41,  44],\n","        ...,\n","        [ 28,  28,  30],\n","        [ 30,  28,  30],\n","        [ 31,  29,  30]],\n","\n","       [[ 65,  71,  72],\n","        [ 67,  70,  71],\n","        [ 69,  69,  70],\n","        ...,\n","        [ 29,  30,  32],\n","        [ 30,  30,  31],\n","        [ 34,  33,  34]],\n","\n","       [[ 47,  46,  49],\n","        [ 50,  44,  47],\n","        [ 51,  40,  43],\n","        ...,\n","        [ 29,  33,  33],\n","        [ 37,  38,  40],\n","        [ 44,  44,  47]]], dtype=uint8)"]},"metadata":{},"execution_count":61}]},{"cell_type":"markdown","source":["## 4.2 Processing Numerical Features"],"metadata":{"id":"Vov-5__C50Bj"}},{"cell_type":"code","source":["class NumericalTransformer(BaseEstimator, TransformerMixin):\n","    # normalize = False: no scaler\n","    # normalize = True: normalize RBG values\n","    def __init__(self, normalize=True, image_height=30, image_width=30):\n","        self.normalize = normalize\n","        self.image_height = image_height\n","        self.image_width = image_width\n","        self.scaler = None\n","\n","    def fit(self, X, y=None):\n","        if self.normalize:\n","          self.scaler = Normalize(255)\n","          self.scaler.fit(X)\n","        return self\n","\n","    # transforming numerical features\n","    def transform(self, X, y=None):\n","        X_copy = []\n","\n","        for img in X:\n","          image = Image.fromarray(img)\n","          image = image.resize((self.image_height,self.image_width))\n","          img = np.array(image)\n","          X_copy.append(img)\n","\n","        X_copy = np.array(X_copy)\n","\n","        if self.normalize:\n","          X_copy = self.scaler.transform(X_copy)\n","\n","        return X_copy"],"metadata":{"id":"WjR3Z52I5oK3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# testing functions\n","fs = FeatureSelector()\n","x_train_fs = fs.fit_transform(x_train)\n","x_train_fs[0]"],"metadata":{"id":"Jl-30AvL5oNC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# testing functions\n","nt = NumericalTransformer(normalize=True, image_height=30, image_width=30)\n","x_train_num = nt.fit_transform(x_train_fs)\n","\n","print(f\"x_train_num.shape: {x_train_num.shape}\")\n","print(f\"x_train_num[0]: {x_train_num[0]}\")"],"metadata":{"id":"k7PFGoI05oQL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 4.3 Pipeline Creation"],"metadata":{"id":"V3hLV1TU7az5"}},{"cell_type":"markdown","source":["The pipeline will only contain the transformations necessary to treat the raw data and get it ready for the training. The neural network training is perfomed as a separate module. Both the pipeline and the NN model are exported to W&B. This way, in order to use our pipeline/model, one needs to pass the raw data through first and then feed it to the trained model to obtain the desired results."],"metadata":{"id":"H3tEVg6A7pnJ"}},{"cell_type":"code","source":["# model = 0 (min-max), 1 (z-score), 2 (no scaling)\n","normalize = True\n","IMAGE_HEIGHT = 30\n","IMAGE_WIDTH = 30\n","\n","# defining the steps in the numerical pipeline\n","numerical_pipeline = Pipeline(steps=[('num_selector', FeatureSelector()),\n","                                     ('num_transformer', NumericalTransformer(normalize=normalize, image_height=IMAGE_HEIGHT, image_width=IMAGE_WIDTH))])\n","\n","# combining numerical and categorical pieplines into one full big pipeline horizontally\n","full_pipeline_preprocessing = FeatureUnion(transformer_list=[\n","                                                             ('num_pipeline', numerical_pipeline)]\n","                                           )"],"metadata":{"id":"IA_-1Dj95oUP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# testing pipeline\n","new_data = full_pipeline_preprocessing.fit_transform(x_train)\n","print(f\"new_data.shape: {new_data.shape}\")\n","print(f\"new_data[0]: {new_data[0]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NIfuf0Ox7ehg","executionInfo":{"status":"ok","timestamp":1658627713935,"user_tz":180,"elapsed":1128,"user":{"displayName":"JÚLIO GOMES","userId":"17557053208840276455"}},"outputId":"ccd7f430-7139-49bd-fc63-3a3076ff80d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["new_data.shape: (10579, 30, 30, 3)\n","new_data[0]: [[[0.56470588 0.50588235 0.56470588]\n","  [0.61960784 0.63137255 0.69411765]\n","  [0.57254902 0.65098039 0.71764706]\n","  ...\n","  [0.15294118 0.1372549  0.17254902]\n","  [0.19607843 0.17254902 0.21568627]\n","  [0.23137255 0.21176471 0.27058824]]\n","\n"," [[0.60392157 0.56078431 0.56862745]\n","  [0.57254902 0.56862745 0.58039216]\n","  [0.54901961 0.58039216 0.61568627]\n","  ...\n","  [0.1254902  0.1254902  0.14901961]\n","  [0.1254902  0.12156863 0.1372549 ]\n","  [0.11764706 0.11764706 0.12941176]]\n","\n"," [[0.54117647 0.50980392 0.49411765]\n","  [0.53333333 0.51372549 0.49803922]\n","  [0.52941176 0.52156863 0.51372549]\n","  ...\n","  [0.15294118 0.16470588 0.18823529]\n","  [0.14901961 0.16078431 0.18039216]\n","  [0.14509804 0.16078431 0.17647059]]\n","\n"," ...\n","\n"," [[0.11372549 0.16470588 0.17647059]\n","  [0.10588235 0.15294118 0.16470588]\n","  [0.10980392 0.15294118 0.16470588]\n","  ...\n","  [0.10980392 0.10980392 0.12156863]\n","  [0.11764706 0.10980392 0.11764706]\n","  [0.12156863 0.11372549 0.11764706]]\n","\n"," [[0.25098039 0.2745098  0.27843137]\n","  [0.25882353 0.27058824 0.2745098 ]\n","  [0.25882353 0.2627451  0.26666667]\n","  ...\n","  [0.11764706 0.12156863 0.12941176]\n","  [0.11764706 0.11764706 0.12156863]\n","  [0.13333333 0.12941176 0.13333333]]\n","\n"," [[0.18823529 0.18431373 0.19607843]\n","  [0.2        0.17647059 0.18823529]\n","  [0.19215686 0.15686275 0.16862745]\n","  ...\n","  [0.11372549 0.13333333 0.13333333]\n","  [0.14117647 0.14509804 0.15294118]\n","  [0.17254902 0.17254902 0.18431373]]]\n"]}]},{"cell_type":"code","source":["x_train = full_pipeline_preprocessing.fit_transform(x_train)\n","x_val = full_pipeline_preprocessing.transform(x_val)\n","\n","print(f\"x_train.shape: {x_train.shape}\")\n","print(f\"x_val.shape: {x_val.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1tV1NMljRto","executionInfo":{"status":"ok","timestamp":1658627715493,"user_tz":180,"elapsed":1561,"user":{"displayName":"JÚLIO GOMES","userId":"17557053208840276455"}},"outputId":"1a8c8804-7593-4052-ca9b-261189d66471"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["x_train.shape: (10579, 30, 30, 3)\n","x_val.shape: (1176, 30, 30, 3)\n"]}]},{"cell_type":"code","source":["run.finish()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["7a14f3b33ac446fab5efc5e568e432d7","a87d19ab61a2457c9f9c295e3f833bce","7a8c24d6b2914d3b9f0aefa49df37fef","cbb09af9d85a4d3c8bd62e3a3c49f582","263ad29c3812436b9cad65530a6186cf","21abedeecff94652a8916f8c424bee50","71b488d87f31422e81b8e719ae2d7f54","dc04d5d8fade4eb5a9a254e21b693fe2"]},"id":"KT_ofXzk8ip9","executionInfo":{"status":"ok","timestamp":1658627570612,"user_tz":180,"elapsed":4291,"user":{"displayName":"JÚLIO GOMES","userId":"17557053208840276455"}},"outputId":"9a032f10-4b9d-4a19-862b-9267f91e08a5"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a14f3b33ac446fab5efc5e568e432d7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">comic-grass-178</strong>: <a href=\"https://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition/runs/1eb8zjzz\" target=\"_blank\">https://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition/runs/1eb8zjzz</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220724_015005-1eb8zjzz/logs</code>"]},"metadata":{}}]},{"cell_type":"markdown","source":["# 5.0 Training"],"metadata":{"id":"q6td4j2Q-5eb"}},{"cell_type":"markdown","source":["## 5.1 Hyperparameter Tuning"],"metadata":{"id":"GXCi7wD6R483"}},{"cell_type":"code","source":["from wandb.keras import WandbCallback"],"metadata":{"id":"VieCjcfUvACb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train():\n","    # Default values for hyper-parameters we're going to sweep over\n","    defaults = dict(\n","                layer_1_kernel_initializer = 'glorot_uniform',\n","                activation_function = 'tanh',\n","                optimizer = 'Adam',\n","                clipnorm = False,\n","                learning_rate = 0.001,\n","                loss = 'categorical_crossentropy',\n","                batch_size = 32,\n","                epochs = 5,\n","                dropout = False,\n","                early_stopping = False,\n","                batch_normalization = 0\n","                )\n","\n","    \n","    # Initialize a new wandb run\n","    wandb.init(project=\"ppgeec-ml-jj/traffic_sign_recognition\", config= defaults)\n","\n","    # Config is a variable that holds and saves hyperparameters and inputs\n","    config = wandb.config\n","\n","\n","    # neural network layers    \n","    lenet5 = Sequential()\n","\n","    # testing the effects of batch-normalization (before activation function)\n","    if config.batch_normalization != 1:\n","      lenet5.add(Conv2D(6, (5,5), strides=1, kernel_initializer=config.layer_1_kernel_initializer, activation=config.activation_function, input_shape=(IMAGE_HEIGHT,IMAGE_WIDTH,3), padding='same')) \n","    else:\n","      lenet5.add(Conv2D(6, (5,5), strides=1, kernel_initializer=config.layer_1_kernel_initializer, input_shape=(IMAGE_HEIGHT,IMAGE_WIDTH,3), padding='same')) \n","      lenet5.add(BatchNormalization())\n","      lenet5.add(Activation(config.activation_function))\n","\n","    # testing the effects of batch-normalization (after activation function)\n","    if config.batch_normalization == 2:\n","      lenet5.add(BatchNormalization())\n","\n","    lenet5.add(AveragePooling2D()) \n","    lenet5.add(Conv2D(16, (5,5), strides=1, activation=config.activation_function, padding='valid'))\n","\n","    # testing the addition of dropout layers\n","    if config.dropout:\n","      lenet5.add(Dropout(rate=0.5))\n","\n","    lenet5.add(AveragePooling2D()) #S4\n","    lenet5.add(Flatten()) #Flatten\n","    lenet5.add(Dense(120, activation=config.activation_function)) #C5\n","\n","    # testing the addition of dropout layers\n","    if config.dropout:\n","      lenet5.add(Dropout(rate=0.5))\n","\n","    lenet5.add(Dense(84, activation=config.activation_function)) #F6\n","\n","    # testing the addition of dropout layers\n","    if config.dropout:\n","      lenet5.add(Dropout(rate=0.25))\n","\n","    lenet5.add(Dense(43, activation='softmax')) #Output layer\n","    # end of neural network layers   \n","\n","    # testing different loss functions\n","    loss = config.loss\n","\n","    # Instantiate an accuracy metric.\n","    accuracy = Accuracy()\n","\n","\n","    # testing optimizer variance effect\n","    # testing learning rate variance \n","    # testing the addition of gradient clipping to avoid exploding gradient\n","    if config.optimizer == 'Adam':\n","      if config.clipnorm:\n","        optimizer = Adam(learning_rate=config.learning_rate, clipnorm=1.0)\n","      else:\n","        optimizer = Adam(learning_rate=config.learning_rate)\n","\n","    if config.optimizer == 'SGD':\n","      if config.clipnorm:\n","        optimizer = SGD(learning_rate=config.learning_rate, clipnorm=1.0)\n","      else:\n","        optimizer = SGD(learning_rate=config.learning_rate)\n","\n","    if config.optimizer == 'RMSprop':\n","      if config.clipnorm:\n","        optimizer = RMSprop(learning_rate=config.learning_rate, clipnorm=1.0)\n","      else:\n","        optimizer = RMSprop(learning_rate=config.learning_rate)\n","\n","\n","\n","    # configure the optimizer, loss, and metrics to monitor.\n","    lenet5.compile(optimizer=optimizer, loss=loss, metrics=['accuracy']) \n","\n","    # testing the effects of early stopping\n","    if config.early_stopping:\n","      es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5) \n","      lenet5.fit(x_train, y_train, \n","              # testing different batch sizes\n","              batch_size=config.batch_size,\n","              # testing epochs variance effect\n","              epochs=config.epochs,\n","              validation_data=(x_val, y_val),\n","              # testing early stopping effect\n","              callbacks=[es, WandbCallback()]\n","              )\n","    else:\n","      lenet5.fit(x_train, y_train, \n","            # testing different batch sizes\n","            batch_size=config.batch_size,\n","            # testing epochs variance effect\n","            epochs=config.epochs,\n","            validation_data=(x_val, y_val),\n","            callbacks=[WandbCallback()]\n","            ) \n","    \n","    # model.save('modelo.h5')"],"metadata":{"id":"uDKI426rCifh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Configure the sweep – specify the parameters to search through, the search strategy, the optimization metric et all.\n","sweep_config = {\n","    'method': 'random', #grid, random\n","    'metric': {\n","      'name': 'accuracy',\n","      'goal': 'maximize'   \n","    },\n","    'parameters': {\n","        # fix exploding gradient with relu (needs 'he_uniform')\n","        'layer_1_kernel_initializer': {\n","            'values': ['glorot_uniform', 'he_uniform']\n","        },\n","        # fix exploding gradient with relu\n","        'activation_function': {\n","            'values': ['tanh', 'relu']\n","        },\n","        # testing learning rate variance effect\n","        'learning_rate': {\n","            'min': -4,\n","            'max': -2,\n","            'distribution': 'log_uniform'\n","        },\n","        # testing optimizer variance effect\n","        'optimizer': {\n","            'values': ['Adam', 'RMSprop', 'SGD']\n","        },\n","        # testing the addition of gradient clipping to avoid exploding gradient\n","        'clipnorm': {\n","            'values': [True, False]\n","        },\n","        # testing epochs variance effect\n","        'epochs': {\n","            'values': [5,10,20]\n","        },\n","        # testing different batch sizes\n","        'batch_size': {\n","            'values': [16,32,64]\n","        },\n","        # testing different loss functions\n","        'loss': {\n","            'values': ['kullback_leibler_divergence',\n","                      'sparse_categorical_crossentropy']\n","        },\n","        # testing the addition of dropout layers\n","        'dropout': {\n","            'values': [True, False]\n","        },\n","        # testing the effects of early stopping\n","        'early_stopping': {\n","            'values': [True, False]\n","        },\n","        # testing the effects of batch-normalization\n","        # 0: no batch-normalization\n","        # 1: batch-normalization before activation function\n","        # 2: batch-normalization after activation function\n","        'batch_normalization': {\n","            'values': [0, 1, 2]\n","        }\n","    }\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, project=\"traffic_sign_recognition\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JOIx8gHvCiia","executionInfo":{"status":"ok","timestamp":1658543299600,"user_tz":180,"elapsed":2298,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"e525d9aa-87c8-4013-e934-c3588e506600"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. learning_rate uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.\n"]},{"output_type":"stream","name":"stdout","text":["Create sweep with ID: ftpjniuf\n","Sweep URL: https://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition/sweeps/ftpjniuf\n"]}]},{"cell_type":"markdown","source":["There is a total of 15,552 combinations of the sweep configuration we created. To save time, we only try 100 of those and select the best one in terms of accuracy."],"metadata":{"id":"9rfWY845R03j"}},{"cell_type":"code","source":["wandb.agent(sweep_id, train, count=100)"],"metadata":{"id":"lTHyYp-2Cinr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"tUPcQM7fCiqM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"rQw4m8haCi20"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"0Qw1YxfvCi5K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"8aSqsywNCi8C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"3ddDAwgbCi-o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"a8uAKS90CjBO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"JCsZw2NUCjDM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"LGUsaroHCjF-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"ECYt9mTjCjI4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5.2 Training Best Model"],"metadata":{"id":"5zI_nnaOUaPS"}},{"cell_type":"markdown","source":["<font color=\"red\">Important</font> to restart the colab to unlink a new experiment (run) with the last ```sweep``` experiment. \n","\n","```\n","Runtime >> Factory reset runtime\n","```\n","> Re-run all cells except for the ones corresponding to neural network training.\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"foJ_gJLNVO8-"}},{"cell_type":"code","source":["# setup wandb\n","wandb.init(project=\"traffic_sign_recognition\",\n","           config={\n","               \"layer_1_kernel_initializer\": 'glorot_uniform',\n","               \"activation_function\": 'tanh',\n","               \"optimizer\": 'SGD',\n","               \"clipnorm\": False,\n","               \"learning_rate\": 0.06645,\n","               \"loss\": 'sparse_categorical_crossentropy',\n","               \"batch_size\": 16,\n","               \"epochs\": 10,\n","               \"dropout\": False,\n","               \"early_stopping\": False,\n","               \"batch_normalization\": 2\n","           })\n","config = wandb.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86},"id":"udIlHisx8HYe","executionInfo":{"status":"ok","timestamp":1658627231367,"user_tz":180,"elapsed":1795,"user":{"displayName":"JÚLIO GOMES","userId":"17557053208840276455"}},"outputId":"c209d167-db2f-47bd-d69c-7cce92d4316a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjuliofreire\u001b[0m (\u001b[33mppgeec-ml-jj\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.21"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20220724_014707-26c0d0vq</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition/runs/26c0d0vq\" target=\"_blank\">flowing-pond-177</a></strong> to <a href=\"https://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}}]},{"cell_type":"code","source":["# neural network layers    \n","lenet5 = Sequential()\n","\n","# testing the effects of batch-normalization (before activation function)\n","if config.batch_normalization != 1:\n","  lenet5.add(Conv2D(6, (5,5), strides=1, kernel_initializer=config.layer_1_kernel_initializer, activation=config.activation_function, input_shape=(IMAGE_HEIGHT,IMAGE_WIDTH,3), padding='same')) \n","else:\n","  lenet5.add(Conv2D(6, (5,5), strides=1, kernel_initializer=config.layer_1_kernel_initializer, input_shape=(IMAGE_HEIGHT,IMAGE_WIDTH,3), padding='same')) \n","  lenet5.add(BatchNormalization())\n","  lenet5.add(Activation(config.activation_function))\n","\n","# testing the effects of batch-normalization (after activation function)\n","if config.batch_normalization == 2:\n","  lenet5.add(BatchNormalization())\n","\n","lenet5.add(AveragePooling2D()) \n","lenet5.add(Conv2D(16, (5,5), strides=1, activation=config.activation_function, padding='valid'))\n","\n","# testing the addition of dropout layers\n","if config.dropout:\n","  lenet5.add(Dropout(rate=0.5))\n","\n","lenet5.add(AveragePooling2D()) #S4\n","lenet5.add(Flatten()) #Flatten\n","lenet5.add(Dense(120, activation=config.activation_function)) #C5\n","\n","# testing the addition of dropout layers\n","if config.dropout:\n","  lenet5.add(Dropout(rate=0.5))\n","\n","lenet5.add(Dense(84, activation=config.activation_function)) #F6\n","\n","# testing the addition of dropout layers\n","if config.dropout:\n","  lenet5.add(Dropout(rate=0.25))\n","\n","lenet5.add(Dense(43, activation='softmax')) #Output layer\n","# end of neural network layers   \n","\n","# testing different loss functions\n","loss = config.loss\n","\n","# Instantiate an accuracy metric.\n","accuracy = Accuracy()\n","\n","\n","# testing optimizer variance effect\n","# testing learning rate variance \n","# testing the addition of gradient clipping to avoid exploding gradient\n","if config.optimizer == 'Adam':\n","  if config.clipnorm:\n","    optimizer = Adam(learning_rate=config.learning_rate, clipnorm=1.0)\n","  else:\n","    optimizer = Adam(learning_rate=config.learning_rate)\n","\n","if config.optimizer == 'SGD':\n","  if config.clipnorm:\n","    optimizer = SGD(learning_rate=config.learning_rate, clipnorm=1.0)\n","  else:\n","    optimizer = SGD(learning_rate=config.learning_rate)\n","\n","if config.optimizer == 'RMSprop':\n","  if config.clipnorm:\n","    optimizer = RMSprop(learning_rate=config.learning_rate, clipnorm=1.0)\n","  else:\n","    optimizer = RMSprop(learning_rate=config.learning_rate)\n","\n","\n","\n","# configure the optimizer, loss, and metrics to monitor.\n","lenet5.compile(optimizer=optimizer, loss=loss, metrics=['accuracy']) \n","\n","# testing the effects of early stopping\n","if config.early_stopping:\n","  es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5) \n","  lenet5.fit(x_train, y_train, \n","          # testing different batch sizes\n","          batch_size=config.batch_size,\n","          # testing epochs variance effect\n","          epochs=config.epochs,\n","          validation_data=(x_val, y_val),\n","          # testing early stopping effect\n","          callbacks=[es, WandbCallback()]\n","          )\n","else:\n","  lenet5.fit(x_train, y_train, \n","        # testing different batch sizes\n","        batch_size=config.batch_size,\n","        # testing epochs variance effect\n","        epochs=config.epochs,\n","        validation_data=(x_val, y_val),\n","        callbacks=[WandbCallback()]\n","        ) \n","\n","lenet5.save('best_model.h5')\n","\n","wandb.finish()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":843,"referenced_widgets":["081572d1df78465cbc441fcab5197229","5c280ed3306040199b90424546597d4b","42d280c7fe3542f8b776be51663dce00","687c53b426c74f368c742640f9a32297","b8f7b46683b248848f27874a10d680a3","04caf498882446c78e8d3db41e7a868c","47874231e64b4c4ab7671f300db966fd","138373577409470cb5024d4dc4102a59"]},"id":"5V1hFBsr90HA","executionInfo":{"status":"ok","timestamp":1658606147879,"user_tz":180,"elapsed":153684,"user":{"displayName":"JÚLIO GOMES","userId":"17557053208840276455"}},"outputId":"5a3c4393-8f5b-460b-b914-5f29334e024f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5214: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"]},{"output_type":"stream","name":"stderr","text":["23-07-2022 19:53:13 From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5214: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","662/662 [==============================] - 16s 23ms/step - loss: 1.2515 - accuracy: 0.6729 - val_loss: 0.5148 - val_accuracy: 0.8690 - _timestamp: 1658606008.0000 - _runtime: 53.0000\n","Epoch 2/10\n","662/662 [==============================] - 15s 22ms/step - loss: 0.3646 - accuracy: 0.9143 - val_loss: 0.3203 - val_accuracy: 0.9260 - _timestamp: 1658606023.0000 - _runtime: 68.0000\n","Epoch 3/10\n","662/662 [==============================] - 15s 22ms/step - loss: 0.2096 - accuracy: 0.9545 - val_loss: 0.2112 - val_accuracy: 0.9498 - _timestamp: 1658606038.0000 - _runtime: 83.0000\n","Epoch 4/10\n","662/662 [==============================] - 15s 22ms/step - loss: 0.1399 - accuracy: 0.9707 - val_loss: 0.1845 - val_accuracy: 0.9515 - _timestamp: 1658606053.0000 - _runtime: 98.0000\n","Epoch 5/10\n","662/662 [==============================] - 15s 22ms/step - loss: 0.0945 - accuracy: 0.9831 - val_loss: 0.1712 - val_accuracy: 0.9541 - _timestamp: 1658606068.0000 - _runtime: 113.0000\n","Epoch 6/10\n","662/662 [==============================] - 15s 22ms/step - loss: 0.0682 - accuracy: 0.9888 - val_loss: 0.1253 - val_accuracy: 0.9668 - _timestamp: 1658606082.0000 - _runtime: 127.0000\n","Epoch 7/10\n","662/662 [==============================] - 15s 22ms/step - loss: 0.0510 - accuracy: 0.9934 - val_loss: 0.1138 - val_accuracy: 0.9626 - _timestamp: 1658606097.0000 - _runtime: 142.0000\n","Epoch 8/10\n","662/662 [==============================] - 15s 22ms/step - loss: 0.0368 - accuracy: 0.9966 - val_loss: 0.0972 - val_accuracy: 0.9728 - _timestamp: 1658606112.0000 - _runtime: 157.0000\n","Epoch 9/10\n","662/662 [==============================] - 15s 22ms/step - loss: 0.0267 - accuracy: 0.9985 - val_loss: 0.0962 - val_accuracy: 0.9685 - _timestamp: 1658606126.0000 - _runtime: 171.0000\n","Epoch 10/10\n","662/662 [==============================] - 15s 22ms/step - loss: 0.0208 - accuracy: 0.9993 - val_loss: 0.0914 - val_accuracy: 0.9711 - _timestamp: 1658606141.0000 - _runtime: 186.0000\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.283 MB of 0.283 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"081572d1df78465cbc441fcab5197229"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇██████</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>loss</td><td>█▃▂▂▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▇▇█▇███</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPS</td><td>0.00076</td></tr><tr><td>accuracy</td><td>0.99934</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.09141</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>loss</td><td>0.0208</td></tr><tr><td>val_accuracy</td><td>0.97109</td></tr><tr><td>val_loss</td><td>0.09141</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">honest-puddle-162</strong>: <a href=\"https://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition/runs/34xmkdgt\" target=\"_blank\">https://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition/runs/34xmkdgt</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220723_195235-34xmkdgt/logs</code>"]},"metadata":{}}]},{"cell_type":"code","source":[""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3pxN2YXOo8gh","executionInfo":{"status":"ok","timestamp":1658606509088,"user_tz":180,"elapsed":1895,"user":{"displayName":"JÚLIO GOMES","userId":"17557053208840276455"}},"outputId":"be530024-2b36-40be-a70e-0c4b598e747e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: best-model.model/assets\n"]},{"output_type":"stream","name":"stderr","text":["23-07-2022 20:01:47 Assets written to: best-model.model/assets\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"rUIW4kiUpu0O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 5.3 Export Best Model to WandB"],"metadata":{"id":"rWTw9zR5UkhG"}},{"cell_type":"code","source":["# types and names of the artifacts\n","artifact_type = \"inference_artifact\"\n","artifact_pipe = \"pipeline\"\n","artifact_model = \"model.h5\""],"metadata":{"id":"tbW7SytCR_q-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["logger.info(\"Dumping the artifacts to disk\")\n","# Save the pipeline using joblib\n","joblib.dump(full_pipeline_preprocessing, artifact_pipe)\n","\n","# Save the model using joblib\n","joblib.dump(best_model, artifact_model)"],"metadata":{"id":"Qlr2sKhmR_wR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658581878704,"user_tz":180,"elapsed":1013,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"915b7379-d410-4a3a-ae96-448c53417066"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["23-07-2022 13:11:17 Dumping the artifacts to disk\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Assets written to: ram://71a042e8-e393-4d66-8894-802e0c73b02e/assets\n"]},{"output_type":"stream","name":"stderr","text":["23-07-2022 13:11:18 Assets written to: ram://71a042e8-e393-4d66-8894-802e0c73b02e/assets\n"]},{"output_type":"execute_result","data":{"text/plain":["['model']"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["print(os.path.getsize('best_model.h5'))\n","print(os.path.getsize('model.h5'))\n","print(os.path.getsize('pipeline'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u6HqUosfIZeZ","executionInfo":{"status":"ok","timestamp":1658581959495,"user_tz":180,"elapsed":29,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"652c16e0-055e-446d-ff5b-05a83b2356e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["295088\n","450845\n","505\n"]}]},{"cell_type":"code","source":["# Pipeline artifact\n","artifact = wandb.Artifact(artifact_pipe,\n","                          type=artifact_type,\n","                          description=\"A full pipeline composed of a Preprocessing Stage\"\n","                          )\n","\n","logger.info(\"Logging model artifact\")\n","artifact.add_file(artifact_pipe)\n","run.log_artifact(artifact)"],"metadata":{"id":"0hIpUkZeVDmk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658581984652,"user_tz":180,"elapsed":27,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"4c3c3314-d1f8-46d7-cd5a-99620a29b67a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["23-07-2022 13:13:03 Logging model artifact\n"]},{"output_type":"execute_result","data":{"text/plain":["<wandb.sdk.wandb_artifacts.Artifact at 0x7f91d383ce90>"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["# Model artifact\n","artifact = wandb.Artifact(artifact_model,\n","                          type=artifact_type,\n","                          description=\"The trained model\"\n","                          )\n","\n","logger.info(\"Logging target enconder artifact\")\n","artifact.add_file(artifact_model)\n","run.log_artifact(artifact)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8uKeGusqKek6","executionInfo":{"status":"ok","timestamp":1658581984656,"user_tz":180,"elapsed":27,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"926655f5-6cda-4d11-f67e-e110ca0758b0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["23-07-2022 13:13:03 Logging target enconder artifact\n"]},{"output_type":"execute_result","data":{"text/plain":["<wandb.sdk.wandb_artifacts.Artifact at 0x7f91d38726d0>"]},"metadata":{},"execution_count":61}]},{"cell_type":"code","source":["run.finish()"],"metadata":{"id":"80FAt0nsVHH0","colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["6296c6e6730a400c9b0d58369be70a38","6294ade44a04443abff93bc4816aa9b2","4475518d40934a3b9737acb9d996cee8","612bc24eba3e4c309bf2abcec5ef614c","c45fa27c348b479dbeb671203274cdf2","6dec1b89936f4ae1b4712127d5cfc863","446598b203524760b992858c83838c1a","6223a6ef3c2444ea89addfc25c39b9f3"]},"executionInfo":{"status":"ok","timestamp":1658582510082,"user_tz":180,"elapsed":3614,"user":{"displayName":"João Lucas Farias","userId":"17118671195830208552"}},"outputId":"ba8f88b7-ef39-4b4e-bf61-687a7e25fca7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.431 MB of 0.431 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6296c6e6730a400c9b0d58369be70a38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Synced <strong style=\"color:#cdcd00\">laced-sun-144</strong>: <a href=\"https://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition/runs/3cqkch1i\" target=\"_blank\">https://wandb.ai/ppgeec-ml-jj/traffic_sign_recognition/runs/3cqkch1i</a><br/>Synced 5 W&B file(s), 0 media file(s), 3 artifact file(s) and 1 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20220723_124609-3cqkch1i/logs</code>"]},"metadata":{}}]}]}